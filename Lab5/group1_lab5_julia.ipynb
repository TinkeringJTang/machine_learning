{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RData, LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, DataStructures, NamedArrays, PrettyTables,\n",
    "        Plots, StatsBase,StatsPlots, GLM\n",
    "import CodecBzip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles, DataFrames, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CategoricalArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>13,913 rows × 23 columns (omitted printing of 14 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>abdt</th><th>tg</th><th>inuidur1</th><th>inuidur2</th><th>female</th><th>black</th><th>hispanic</th><th>othrace</th><th>dep</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>10824.0</td><td>0.0</td><td>18.0</td><td>18.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>2</th><td>10635.0</td><td>2.0</td><td>7.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>10551.0</td><td>5.0</td><td>18.0</td><td>6.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>10824.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>10747.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>10544.0</td><td>6.0</td><td>7.0</td><td>7.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>10845.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>10670.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>9</th><td>10768.0</td><td>3.0</td><td>28.0</td><td>11.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>10754.0</td><td>2.0</td><td>20.0</td><td>20.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>10712.0</td><td>3.0</td><td>6.0</td><td>6.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>12</th><td>10607.0</td><td>4.0</td><td>9.0</td><td>9.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>10831.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>14</th><td>10845.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>10831.0</td><td>0.0</td><td>9.0</td><td>9.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>16</th><td>10551.0</td><td>3.0</td><td>27.0</td><td>27.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>10859.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>18</th><td>10740.0</td><td>1.0</td><td>15.0</td><td>15.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>19</th><td>10537.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>10663.0</td><td>6.0</td><td>26.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>10656.0</td><td>5.0</td><td>30.0</td><td>9.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>22</th><td>10628.0</td><td>2.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>10516.0</td><td>0.0</td><td>15.0</td><td>15.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>10803.0</td><td>2.0</td><td>3.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>10663.0</td><td>0.0</td><td>28.0</td><td>11.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>10747.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>27</th><td>10551.0</td><td>4.0</td><td>22.0</td><td>22.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td></tr><tr><th>28</th><td>10635.0</td><td>2.0</td><td>17.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>10761.0</td><td>2.0</td><td>13.0</td><td>13.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>10586.0</td><td>1.0</td><td>8.0</td><td>8.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& abdt & tg & inuidur1 & inuidur2 & female & black & hispanic & othrace & dep & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 10824.0 & 0.0 & 18.0 & 18.0 & 0.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t2 & 10635.0 & 2.0 & 7.0 & 3.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 10551.0 & 5.0 & 18.0 & 6.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 10824.0 & 0.0 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 10747.0 & 0.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 10544.0 & 6.0 & 7.0 & 7.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 10845.0 & 1.0 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 10670.0 & 3.0 & 3.0 & 3.0 & 1.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t9 & 10768.0 & 3.0 & 28.0 & 11.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 10754.0 & 2.0 & 20.0 & 20.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 10712.0 & 3.0 & 6.0 & 6.0 & 0.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t12 & 10607.0 & 4.0 & 9.0 & 9.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 10831.0 & 0.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t14 & 10845.0 & 0.0 & 27.0 & 27.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 10831.0 & 0.0 & 9.0 & 9.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t16 & 10551.0 & 3.0 & 27.0 & 27.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 10859.0 & 0.0 & 27.0 & 27.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t18 & 10740.0 & 1.0 & 15.0 & 15.0 & 1.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t19 & 10537.0 & 1.0 & 1.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 10663.0 & 6.0 & 26.0 & 26.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 10656.0 & 5.0 & 30.0 & 9.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t22 & 10628.0 & 2.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 10516.0 & 0.0 & 15.0 & 15.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 10803.0 & 2.0 & 3.0 & 3.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 10663.0 & 0.0 & 28.0 & 11.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 10747.0 & 0.0 & 12.0 & 12.0 & 1.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t27 & 10551.0 & 4.0 & 22.0 & 22.0 & 1.0 & 0.0 & 1.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t28 & 10635.0 & 2.0 & 17.0 & 10.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 10761.0 & 2.0 & 13.0 & 13.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 10586.0 & 1.0 & 8.0 & 8.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m13913×23 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m abdt    \u001b[0m\u001b[1m tg      \u001b[0m\u001b[1m inuidur1 \u001b[0m\u001b[1m inuidur2 \u001b[0m\u001b[1m female  \u001b[0m\u001b[1m black   \u001b[0m\u001b[1m hispanic \u001b[0m\u001b[1m oth\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │ 10824.0      0.0      18.0      18.0      0.0      0.0       0.0      ⋯\n",
       "     2 │ 10635.0      2.0       7.0       3.0      0.0      0.0       0.0\n",
       "     3 │ 10551.0      5.0      18.0       6.0      1.0      0.0       0.0\n",
       "     4 │ 10824.0      0.0       1.0       1.0      0.0      0.0       0.0\n",
       "     5 │ 10747.0      0.0      27.0      27.0      0.0      0.0       0.0      ⋯\n",
       "     6 │ 10544.0      6.0       7.0       7.0      0.0      0.0       0.0\n",
       "     7 │ 10845.0      1.0       1.0       1.0      0.0      0.0       0.0\n",
       "     8 │ 10670.0      3.0       3.0       3.0      1.0      0.0       0.0\n",
       "     9 │ 10768.0      3.0      28.0      11.0      1.0      0.0       0.0      ⋯\n",
       "    10 │ 10754.0      2.0      20.0      20.0      1.0      0.0       0.0\n",
       "    11 │ 10712.0      3.0       6.0       6.0      0.0      0.0       0.0\n",
       "   ⋮   │    ⋮        ⋮        ⋮         ⋮         ⋮        ⋮        ⋮          ⋱\n",
       " 13904 │ 10747.0      3.0      15.0      15.0      1.0      0.0       1.0\n",
       " 13905 │ 10628.0      4.0      10.0      10.0      0.0      0.0       1.0      ⋯\n",
       " 13906 │ 10523.0      4.0       4.0       4.0      0.0      0.0       1.0\n",
       " 13907 │ 10558.0      0.0       9.0       9.0      0.0      0.0       0.0\n",
       " 13908 │ 10621.0      1.0       1.0       1.0      0.0      0.0       0.0\n",
       " 13909 │ 10831.0      5.0      27.0      27.0      0.0      0.0       0.0      ⋯\n",
       " 13910 │ 10677.0      2.0       4.0       4.0      1.0      0.0       0.0\n",
       " 13911 │ 10817.0      4.0       4.0       4.0      0.0      0.0       0.0\n",
       " 13912 │ 10691.0      0.0      27.0      27.0      0.0      0.0       0.0\n",
       " 13913 │ 10677.0      5.0      25.0      25.0      0.0      0.0       0.0      ⋯\n",
       "\u001b[36m                                               16 columns and 13892 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat, head = readdlm(\"GitHub/ECO224/data/penn_jae.dat\", header=true, Float64)\n",
    "mat\n",
    "df =DataFrame(mat, vec(head))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only rows which have tg = 0 or 4\n",
    "penn = filter(row -> row[:tg] in [4,0], df)\n",
    "\n",
    "replace!(penn.tg, 4 => 1)\n",
    "rename!(penn, \"tg\" => \"T4\")\n",
    "\n",
    "# from float to string\n",
    "penn[!,:dep] = string.(penn[!,:dep]) \n",
    "\n",
    "# dep varaible in categorical format \n",
    "penn[!,:dep] = categorical(penn[!,:dep]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to make an OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boot_fn (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function boot_fn(data,index)\n",
    "            ols_1 = lm(@formula(log(inuidur1)~T4+ (female+black+othrace+dep+q2+q3+q4+q5+q6+agelt35+agegt54+durable+lusd+husd)), penn[index,:])\n",
    "            T4 = GLM.coeftable(ols_1).cols[1][2]\n",
    "            female = GLM.coeftable(ols_1).cols[1][3]\n",
    "            black = GLM.coeftable(ols_1).cols[1][4]\n",
    "            return [T4, female, black]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function selects observations randomly, with replacement, and then passes it as an argument to boot_fn (bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boot_2 (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function boot_2(data,func,R)\n",
    "            T4_coef = []\n",
    "            fem_coef = []\n",
    "            black_coef = []\n",
    "            for i in 1:R\n",
    "                append!(T4_coef,func(data,sample([1:5099;], 5099, replace = true))[1])\n",
    "                append!(fem_coef,func(data,sample([1:5099;], 5099, replace = true))[2])\n",
    "                append!(black_coef,func(data,sample([1:5099;], 5099, replace = true))[3])\n",
    "            end\n",
    "        table = NamedArray(zeros(3, 3))\n",
    "\n",
    "        table[1,2] = mean(T4_coef)\n",
    "        table[1,3] = std(T4_coef, corrected=true)\n",
    "        table[2,2] = mean(fem_coef)\n",
    "        table[2,3] = std(fem_coef, corrected=true)\n",
    "        table[3,2] = mean(black_coef)\n",
    "        table[3,3] = std(black_coef, corrected=true)\n",
    "        T = DataFrame(table, [ :\"Variable\", :\"Coefficient (boostrap)\", :\"Standard error (boostrap)\"]) \n",
    "        T[!,:Variable] = string.(T[!,:Variable]) \n",
    "\n",
    "        T[1,1] = \"T4\"\n",
    "        T[2,1] = \"Female\"\n",
    "        T[3,1] = \"Black\"\n",
    "        \n",
    "        bootstrap_statistics = Dict{String,Any}(\"Table\" => T, \"T4\" => T4_coef, \"Female\" => fem_coef, \"Black\" => black_coef)\n",
    "    return bootstrap_statistics\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just checking the function is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       ":(log(inuidur1)) ~ 1 + T4 + female + black + othrace + dep + q2 + q3 + q4 + q5 + q6 + agelt35 + agegt54 + durable + lusd + husd\n",
       "\n",
       "Coefficients:\n",
       "───────────────────────────────────────────────────────────────────────────────\n",
       "                   Coef.  Std. Error      t  Pr(>|t|)    Lower 95%    Upper 95%\n",
       "───────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   2.17846      0.159015   13.70    <1e-41   1.86672      2.4902\n",
       "T4           -0.0716925    0.0354633  -2.02    0.0433  -0.141216    -0.00216922\n",
       "female        0.126368     0.0348249   3.63    0.0003   0.0580965    0.19464\n",
       "black        -0.293768     0.0529756  -5.55    <1e-07  -0.397623    -0.189913\n",
       "othrace      -0.472445     0.198398   -2.38    0.0173  -0.86139     -0.0835005\n",
       "dep: 1.0      0.0298669    0.0541402   0.55    0.5812  -0.0762713    0.136005\n",
       "dep: 2.0      0.0961865    0.0468623   2.05    0.0402   0.00431626   0.188057\n",
       "q2            0.0736781    0.156826    0.47    0.6385  -0.233768     0.381124\n",
       "q3           -0.0385065    0.156478   -0.25    0.8056  -0.345271     0.268258\n",
       "q4           -0.0549492    0.15656    -0.35    0.7256  -0.361875     0.251976\n",
       "q5           -0.144178     0.155888   -0.92    0.3551  -0.449785     0.16143\n",
       "q6            0.00336132   0.166456    0.02    0.9839  -0.322964     0.329686\n",
       "agelt35      -0.162772     0.036965   -4.40    <1e-04  -0.23524     -0.0903048\n",
       "agegt54       0.229667     0.0591717   3.88    0.0001   0.113665     0.345669\n",
       "durable       0.126557     0.0481459   2.63    0.0086   0.0321707    0.220944\n",
       "lusd         -0.175353     0.0409825  -4.28    <1e-04  -0.255696    -0.0950092\n",
       "husd         -0.105225     0.0449086  -2.34    0.0192  -0.193265    -0.0171844\n",
       "───────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(@formula(log(inuidur1)~T4+ (female+black+othrace+dep+q2+q3+q4+q5+q6+agelt35+agegt54+durable+lusd+husd)), penn[1:5099,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>Variable</th><th>Coefficient (boostrap)</th><th>Standard error (boostrap)</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>T4</td><td>-0.0731726</td><td>0.0372499</td></tr><tr><th>2</th><td>Female</td><td>0.126347</td><td>0.0339095</td></tr><tr><th>3</th><td>Black</td><td>-0.293819</td><td>0.0597755</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Variable & Coefficient (boostrap) & Standard error (boostrap)\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & T4 & -0.0731726 & 0.0372499 \\\\\n",
       "\t2 & Female & 0.126347 & 0.0339095 \\\\\n",
       "\t3 & Black & -0.293819 & 0.0597755 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Variable \u001b[0m\u001b[1m Coefficient (boostrap) \u001b[0m\u001b[1m Standard error (boostrap) \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String   \u001b[0m\u001b[90m Float64                \u001b[0m\u001b[90m Float64                   \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────────────────\n",
       "   1 │ T4                    -0.0731726                  0.0372499\n",
       "   2 │ Female                 0.126347                   0.0339095\n",
       "   3 │ Black                 -0.293819                   0.0597755"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_2(penn,boot_fn,1000)[\"Table\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "rdata_read = RData.load(\"GitHub/ECO224/data/cps2012.RData\")\n",
    "data = rdata_read[\"data\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormulaTerm\n",
       "Response:\n",
       "  lnw(unknown)\n",
       "Predictors:\n",
       "  female(unknown)\n",
       "  widowed(unknown)\n",
       "  divorced(unknown)\n",
       "  separated(unknown)\n",
       "  nevermarried(unknown)\n",
       "  hsd08(unknown)\n",
       "  hsd911(unknown)\n",
       "  hsg(unknown)\n",
       "  cg(unknown)\n",
       "  ad(unknown)\n",
       "  mw(unknown)\n",
       "  so(unknown)\n",
       "  we(unknown)\n",
       "  exp1(unknown)\n",
       "  exp2(unknown)\n",
       "  exp3(unknown)\n",
       "  female(unknown) & widowed(unknown)\n",
       "  female(unknown) & divorced(unknown)\n",
       "  female(unknown) & separated(unknown)\n",
       "  female(unknown) & nevermarried(unknown)\n",
       "  female(unknown) & hsd08(unknown)\n",
       "  female(unknown) & hsd911(unknown)\n",
       "  female(unknown) & hsg(unknown)\n",
       "  female(unknown) & cg(unknown)\n",
       "  female(unknown) & ad(unknown)\n",
       "  female(unknown) & mw(unknown)\n",
       "  female(unknown) & so(unknown)\n",
       "  female(unknown) & we(unknown)\n",
       "  female(unknown) & exp1(unknown)\n",
       "  female(unknown) & exp2(unknown)\n",
       "  female(unknown) & exp3(unknown)\n",
       "  widowed(unknown) & widowed(unknown)\n",
       "  widowed(unknown) & divorced(unknown)\n",
       "  widowed(unknown) & separated(unknown)\n",
       "  widowed(unknown) & nevermarried(unknown)\n",
       "  widowed(unknown) & hsd08(unknown)\n",
       "  widowed(unknown) & hsd911(unknown)\n",
       "  widowed(unknown) & hsg(unknown)\n",
       "  widowed(unknown) & cg(unknown)\n",
       "  widowed(unknown) & ad(unknown)\n",
       "  widowed(unknown) & mw(unknown)\n",
       "  widowed(unknown) & so(unknown)\n",
       "  widowed(unknown) & we(unknown)\n",
       "  widowed(unknown) & exp1(unknown)\n",
       "  widowed(unknown) & exp2(unknown)\n",
       "  widowed(unknown) & exp3(unknown)\n",
       "  divorced(unknown) & widowed(unknown)\n",
       "  divorced(unknown) & divorced(unknown)\n",
       "  divorced(unknown) & separated(unknown)\n",
       "  divorced(unknown) & nevermarried(unknown)\n",
       "  divorced(unknown) & hsd08(unknown)\n",
       "  divorced(unknown) & hsd911(unknown)\n",
       "  divorced(unknown) & hsg(unknown)\n",
       "  divorced(unknown) & cg(unknown)\n",
       "  divorced(unknown) & ad(unknown)\n",
       "  divorced(unknown) & mw(unknown)\n",
       "  divorced(unknown) & so(unknown)\n",
       "  divorced(unknown) & we(unknown)\n",
       "  divorced(unknown) & exp1(unknown)\n",
       "  divorced(unknown) & exp2(unknown)\n",
       "  divorced(unknown) & exp3(unknown)\n",
       "  separated(unknown) & widowed(unknown)\n",
       "  separated(unknown) & divorced(unknown)\n",
       "  separated(unknown) & separated(unknown)\n",
       "  separated(unknown) & nevermarried(unknown)\n",
       "  separated(unknown) & hsd08(unknown)\n",
       "  separated(unknown) & hsd911(unknown)\n",
       "  separated(unknown) & hsg(unknown)\n",
       "  separated(unknown) & cg(unknown)\n",
       "  separated(unknown) & ad(unknown)\n",
       "  separated(unknown) & mw(unknown)\n",
       "  separated(unknown) & so(unknown)\n",
       "  separated(unknown) & we(unknown)\n",
       "  separated(unknown) & exp1(unknown)\n",
       "  separated(unknown) & exp2(unknown)\n",
       "  separated(unknown) & exp3(unknown)\n",
       "  nevermarried(unknown) & widowed(unknown)\n",
       "  nevermarried(unknown) & divorced(unknown)\n",
       "  nevermarried(unknown) & separated(unknown)\n",
       "  nevermarried(unknown) & nevermarried(unknown)\n",
       "  nevermarried(unknown) & hsd08(unknown)\n",
       "  nevermarried(unknown) & hsd911(unknown)\n",
       "  nevermarried(unknown) & hsg(unknown)\n",
       "  nevermarried(unknown) & cg(unknown)\n",
       "  nevermarried(unknown) & ad(unknown)\n",
       "  nevermarried(unknown) & mw(unknown)\n",
       "  nevermarried(unknown) & so(unknown)\n",
       "  nevermarried(unknown) & we(unknown)\n",
       "  nevermarried(unknown) & exp1(unknown)\n",
       "  nevermarried(unknown) & exp2(unknown)\n",
       "  nevermarried(unknown) & exp3(unknown)\n",
       "  hsd08(unknown) & widowed(unknown)\n",
       "  hsd08(unknown) & divorced(unknown)\n",
       "  hsd08(unknown) & separated(unknown)\n",
       "  hsd08(unknown) & nevermarried(unknown)\n",
       "  hsd08(unknown) & hsd08(unknown)\n",
       "  hsd08(unknown) & hsd911(unknown)\n",
       "  hsd08(unknown) & hsg(unknown)\n",
       "  hsd08(unknown) & cg(unknown)\n",
       "  hsd08(unknown) & ad(unknown)\n",
       "  hsd08(unknown) & mw(unknown)\n",
       "  hsd08(unknown) & so(unknown)\n",
       "  hsd08(unknown) & we(unknown)\n",
       "  hsd08(unknown) & exp1(unknown)\n",
       "  hsd08(unknown) & exp2(unknown)\n",
       "  hsd08(unknown) & exp3(unknown)\n",
       "  hsd911(unknown) & widowed(unknown)\n",
       "  hsd911(unknown) & divorced(unknown)\n",
       "  hsd911(unknown) & separated(unknown)\n",
       "  hsd911(unknown) & nevermarried(unknown)\n",
       "  hsd911(unknown) & hsd08(unknown)\n",
       "  hsd911(unknown) & hsd911(unknown)\n",
       "  hsd911(unknown) & hsg(unknown)\n",
       "  hsd911(unknown) & cg(unknown)\n",
       "  hsd911(unknown) & ad(unknown)\n",
       "  hsd911(unknown) & mw(unknown)\n",
       "  hsd911(unknown) & so(unknown)\n",
       "  hsd911(unknown) & we(unknown)\n",
       "  hsd911(unknown) & exp1(unknown)\n",
       "  hsd911(unknown) & exp2(unknown)\n",
       "  hsd911(unknown) & exp3(unknown)\n",
       "  hsg(unknown) & widowed(unknown)\n",
       "  hsg(unknown) & divorced(unknown)\n",
       "  hsg(unknown) & separated(unknown)\n",
       "  hsg(unknown) & nevermarried(unknown)\n",
       "  hsg(unknown) & hsd08(unknown)\n",
       "  hsg(unknown) & hsd911(unknown)\n",
       "  hsg(unknown) & hsg(unknown)\n",
       "  hsg(unknown) & cg(unknown)\n",
       "  hsg(unknown) & ad(unknown)\n",
       "  hsg(unknown) & mw(unknown)\n",
       "  hsg(unknown) & so(unknown)\n",
       "  hsg(unknown) & we(unknown)\n",
       "  hsg(unknown) & exp1(unknown)\n",
       "  hsg(unknown) & exp2(unknown)\n",
       "  hsg(unknown) & exp3(unknown)\n",
       "  cg(unknown) & widowed(unknown)\n",
       "  cg(unknown) & divorced(unknown)\n",
       "  cg(unknown) & separated(unknown)\n",
       "  cg(unknown) & nevermarried(unknown)\n",
       "  cg(unknown) & hsd08(unknown)\n",
       "  cg(unknown) & hsd911(unknown)\n",
       "  cg(unknown) & hsg(unknown)\n",
       "  cg(unknown) & cg(unknown)\n",
       "  cg(unknown) & ad(unknown)\n",
       "  cg(unknown) & mw(unknown)\n",
       "  cg(unknown) & so(unknown)\n",
       "  cg(unknown) & we(unknown)\n",
       "  cg(unknown) & exp1(unknown)\n",
       "  cg(unknown) & exp2(unknown)\n",
       "  cg(unknown) & exp3(unknown)\n",
       "  ad(unknown) & widowed(unknown)\n",
       "  ad(unknown) & divorced(unknown)\n",
       "  ad(unknown) & separated(unknown)\n",
       "  ad(unknown) & nevermarried(unknown)\n",
       "  ad(unknown) & hsd08(unknown)\n",
       "  ad(unknown) & hsd911(unknown)\n",
       "  ad(unknown) & hsg(unknown)\n",
       "  ad(unknown) & cg(unknown)\n",
       "  ad(unknown) & ad(unknown)\n",
       "  ad(unknown) & mw(unknown)\n",
       "  ad(unknown) & so(unknown)\n",
       "  ad(unknown) & we(unknown)\n",
       "  ad(unknown) & exp1(unknown)\n",
       "  ad(unknown) & exp2(unknown)\n",
       "  ad(unknown) & exp3(unknown)\n",
       "  mw(unknown) & widowed(unknown)\n",
       "  mw(unknown) & divorced(unknown)\n",
       "  mw(unknown) & separated(unknown)\n",
       "  mw(unknown) & nevermarried(unknown)\n",
       "  mw(unknown) & hsd08(unknown)\n",
       "  mw(unknown) & hsd911(unknown)\n",
       "  mw(unknown) & hsg(unknown)\n",
       "  mw(unknown) & cg(unknown)\n",
       "  mw(unknown) & ad(unknown)\n",
       "  mw(unknown) & mw(unknown)\n",
       "  mw(unknown) & so(unknown)\n",
       "  mw(unknown) & we(unknown)\n",
       "  mw(unknown) & exp1(unknown)\n",
       "  mw(unknown) & exp2(unknown)\n",
       "  mw(unknown) & exp3(unknown)\n",
       "  so(unknown) & widowed(unknown)\n",
       "  so(unknown) & divorced(unknown)\n",
       "  so(unknown) & separated(unknown)\n",
       "  so(unknown) & nevermarried(unknown)\n",
       "  so(unknown) & hsd08(unknown)\n",
       "  so(unknown) & hsd911(unknown)\n",
       "  so(unknown) & hsg(unknown)\n",
       "  so(unknown) & cg(unknown)\n",
       "  so(unknown) & ad(unknown)\n",
       "  so(unknown) & mw(unknown)\n",
       "  so(unknown) & so(unknown)\n",
       "  so(unknown) & we(unknown)\n",
       "  so(unknown) & exp1(unknown)\n",
       "  so(unknown) & exp2(unknown)\n",
       "  so(unknown) & exp3(unknown)\n",
       "  we(unknown) & widowed(unknown)\n",
       "  we(unknown) & divorced(unknown)\n",
       "  we(unknown) & separated(unknown)\n",
       "  we(unknown) & nevermarried(unknown)\n",
       "  we(unknown) & hsd08(unknown)\n",
       "  we(unknown) & hsd911(unknown)\n",
       "  we(unknown) & hsg(unknown)\n",
       "  we(unknown) & cg(unknown)\n",
       "  we(unknown) & ad(unknown)\n",
       "  we(unknown) & mw(unknown)\n",
       "  we(unknown) & so(unknown)\n",
       "  we(unknown) & we(unknown)\n",
       "  we(unknown) & exp1(unknown)\n",
       "  we(unknown) & exp2(unknown)\n",
       "  we(unknown) & exp3(unknown)\n",
       "  exp1(unknown) & widowed(unknown)\n",
       "  exp1(unknown) & divorced(unknown)\n",
       "  exp1(unknown) & separated(unknown)\n",
       "  exp1(unknown) & nevermarried(unknown)\n",
       "  exp1(unknown) & hsd08(unknown)\n",
       "  exp1(unknown) & hsd911(unknown)\n",
       "  exp1(unknown) & hsg(unknown)\n",
       "  exp1(unknown) & cg(unknown)\n",
       "  exp1(unknown) & ad(unknown)\n",
       "  exp1(unknown) & mw(unknown)\n",
       "  exp1(unknown) & so(unknown)\n",
       "  exp1(unknown) & we(unknown)\n",
       "  exp1(unknown) & exp1(unknown)\n",
       "  exp1(unknown) & exp2(unknown)\n",
       "  exp1(unknown) & exp3(unknown)\n",
       "  exp2(unknown) & widowed(unknown)\n",
       "  exp2(unknown) & divorced(unknown)\n",
       "  exp2(unknown) & separated(unknown)\n",
       "  exp2(unknown) & nevermarried(unknown)\n",
       "  exp2(unknown) & hsd08(unknown)\n",
       "  exp2(unknown) & hsd911(unknown)\n",
       "  exp2(unknown) & hsg(unknown)\n",
       "  exp2(unknown) & cg(unknown)\n",
       "  exp2(unknown) & ad(unknown)\n",
       "  exp2(unknown) & mw(unknown)\n",
       "  exp2(unknown) & so(unknown)\n",
       "  exp2(unknown) & we(unknown)\n",
       "  exp2(unknown) & exp1(unknown)\n",
       "  exp2(unknown) & exp2(unknown)\n",
       "  exp2(unknown) & exp3(unknown)\n",
       "  exp3(unknown) & widowed(unknown)\n",
       "  exp3(unknown) & divorced(unknown)\n",
       "  exp3(unknown) & separated(unknown)\n",
       "  exp3(unknown) & nevermarried(unknown)\n",
       "  exp3(unknown) & hsd08(unknown)\n",
       "  exp3(unknown) & hsd911(unknown)\n",
       "  exp3(unknown) & hsg(unknown)\n",
       "  exp3(unknown) & cg(unknown)\n",
       "  exp3(unknown) & ad(unknown)\n",
       "  exp3(unknown) & mw(unknown)\n",
       "  exp3(unknown) & so(unknown)\n",
       "  exp3(unknown) & we(unknown)\n",
       "  exp3(unknown) & exp1(unknown)\n",
       "  exp3(unknown) & exp2(unknown)\n",
       "  exp3(unknown) & exp3(unknown)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic model\n",
    "formula_basic = @formula(lnw ~ female + female*(widowed + divorced + separated + nevermarried +\n",
    "hsd08 + hsd911 + hsg + cg + ad + mw + so + we + exp1 + exp2 + exp3))\n",
    "\n",
    "#Flexible model\n",
    "formula_flex  = @formula(lnw ~ female + female*(widowed + divorced + separated + nevermarried + hsd08 + hsd911 + hsg + cg + ad + \n",
    "        mw + so + we + exp1 + exp2 + exp3) + (widowed + divorced + separated + nevermarried + hsd08 + hsd911 + hsg + cg + \n",
    "        ad + mw + so +we + exp1 + exp2 + exp3)*(widowed + divorced + separated + nevermarried + hsd08 + hsd911 + hsg + cg + \n",
    "        ad + mw + so +we + exp1 + exp2 + exp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the data in two. One to get the coefficients and another one to test them (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>7,305 rows × 23 columns (omitted printing of 15 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>year</th><th>lnw</th><th>female</th><th>widowed</th><th>divorced</th><th>separated</th><th>nevermarried</th><th>hsd08</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>2012.0</td><td>1.36577</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>2012.0</td><td>2.54022</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>2012.0</td><td>3.14226</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>2012.0</td><td>2.43361</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>2012.0</td><td>2.65676</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>2012.0</td><td>2.43361</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>7</th><td>2012.0</td><td>2.05094</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>8</th><td>2012.0</td><td>2.49424</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>2012.0</td><td>3.92972</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>2012.0</td><td>2.0124</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>2012.0</td><td>2.11021</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>2012.0</td><td>2.83908</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>2012.0</td><td>3.06222</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>2012.0</td><td>2.59222</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>2012.0</td><td>2.43361</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>2012.0</td><td>1.69666</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>17</th><td>2012.0</td><td>2.65676</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>18</th><td>2012.0</td><td>2.51651</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>2012.0</td><td>1.8683</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>2012.0</td><td>2.09257</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>2012.0</td><td>2.97521</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>22</th><td>2012.0</td><td>2.65676</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>23</th><td>2012.0</td><td>2.83908</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>24</th><td>2012.0</td><td>2.95686</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>2012.0</td><td>2.53897</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>2012.0</td><td>3.33873</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>2012.0</td><td>2.51366</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>2012.0</td><td>2.00283</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>2012.0</td><td>2.95834</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>2012.0</td><td>2.52323</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& year & lnw & female & widowed & divorced & separated & nevermarried & hsd08 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2012.0 & 1.36577 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 2012.0 & 2.54022 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 2012.0 & 3.14226 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 2012.0 & 2.43361 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 2012.0 & 2.65676 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 2012.0 & 2.43361 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 2012.0 & 2.05094 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 2012.0 & 2.49424 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 2012.0 & 3.92972 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 2012.0 & 2.0124 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 2012.0 & 2.11021 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 2012.0 & 2.83908 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 2012.0 & 3.06222 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 2012.0 & 2.59222 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 2012.0 & 2.43361 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 2012.0 & 1.69666 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 2012.0 & 2.65676 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 2012.0 & 2.51651 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 2012.0 & 1.8683 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 2012.0 & 2.09257 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 2012.0 & 2.97521 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 2012.0 & 2.65676 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 2012.0 & 2.83908 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 2012.0 & 2.95686 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 2012.0 & 2.53897 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 2012.0 & 3.33873 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 2012.0 & 2.51366 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 2012.0 & 2.00283 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 2012.0 & 2.95834 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 2012.0 & 2.52323 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m7305×23 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m year    \u001b[0m\u001b[1m lnw     \u001b[0m\u001b[1m female  \u001b[0m\u001b[1m widowed \u001b[0m\u001b[1m divorced \u001b[0m\u001b[1m separated \u001b[0m\u001b[1m nevermarried \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │  2012.0  1.36577      1.0      0.0       0.0        0.0           0.0  ⋯\n",
       "    2 │  2012.0  2.54022      0.0      0.0       0.0        0.0           0.0\n",
       "    3 │  2012.0  3.14226      1.0      0.0       1.0        0.0           0.0\n",
       "    4 │  2012.0  2.43361      0.0      0.0       0.0        0.0           0.0\n",
       "    5 │  2012.0  2.65676      1.0      0.0       0.0        0.0           0.0  ⋯\n",
       "    6 │  2012.0  2.43361      0.0      0.0       0.0        0.0           1.0\n",
       "    7 │  2012.0  2.05094      1.0      0.0       0.0        0.0           1.0\n",
       "    8 │  2012.0  2.49424      0.0      0.0       0.0        0.0           0.0\n",
       "    9 │  2012.0  3.92972      1.0      0.0       0.0        0.0           0.0  ⋯\n",
       "   10 │  2012.0  2.0124       1.0      0.0       0.0        0.0           0.0\n",
       "   11 │  2012.0  2.11021      0.0      0.0       0.0        0.0           0.0\n",
       "  ⋮   │    ⋮        ⋮        ⋮        ⋮        ⋮          ⋮           ⋮        ⋱\n",
       " 7296 │  2012.0  3.14226      1.0      0.0       0.0        0.0           1.0\n",
       " 7297 │  2012.0  3.28537      0.0      0.0       0.0        0.0           0.0  ⋯\n",
       " 7298 │  2012.0  2.18675      0.0      0.0       0.0        0.0           1.0\n",
       " 7299 │  2012.0  2.77454      1.0      0.0       0.0        0.0           0.0\n",
       " 7300 │  2012.0  2.8799       1.0      0.0       0.0        0.0           0.0\n",
       " 7301 │  2012.0  3.28537      0.0      0.0       0.0        0.0           0.0  ⋯\n",
       " 7302 │  2012.0  2.70555      1.0      0.0       0.0        0.0           0.0\n",
       " 7303 │  2012.0  3.97851      0.0      0.0       0.0        0.0           1.0\n",
       " 7304 │  2012.0  2.72562      1.0      0.0       0.0        0.0           0.0\n",
       " 7305 │  2012.0  3.14226      0.0      0.0       0.0        0.0           0.0  ⋯\n",
       "\u001b[36m                                                16 columns and 7284 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training = sample( collect(1:nrow( data ) ), trunc(Int, 3 * nrow( data ) / 4 ),  replace= false )\n",
    "\n",
    "data_train = data[ vec(training), : ]\n",
    "data_test = data[ Not(training), : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_X_basic_train = ModelMatrix(ModelFrame(formula_basic,data_train)).m\n",
    "model_X_basic_test = ModelMatrix(ModelFrame(formula_basic,data_test)).m\n",
    "p_basic = size(model_X_basic_test)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_X_flex_train = ModelMatrix(ModelFrame(formula_flex,data_train)).m\n",
    "model_X_flex_test = ModelMatrix(ModelFrame(formula_flex,data_test)).m\n",
    "p_flex = size(model_X_flex_test)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>7,305 rows × 1 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>lnw</th></tr><tr><th></th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1.36577</td></tr><tr><th>2</th><td>2.54022</td></tr><tr><th>3</th><td>3.14226</td></tr><tr><th>4</th><td>2.43361</td></tr><tr><th>5</th><td>2.65676</td></tr><tr><th>6</th><td>2.43361</td></tr><tr><th>7</th><td>2.05094</td></tr><tr><th>8</th><td>2.49424</td></tr><tr><th>9</th><td>3.92972</td></tr><tr><th>10</th><td>2.0124</td></tr><tr><th>11</th><td>2.11021</td></tr><tr><th>12</th><td>2.83908</td></tr><tr><th>13</th><td>3.06222</td></tr><tr><th>14</th><td>2.59222</td></tr><tr><th>15</th><td>2.43361</td></tr><tr><th>16</th><td>1.69666</td></tr><tr><th>17</th><td>2.65676</td></tr><tr><th>18</th><td>2.51651</td></tr><tr><th>19</th><td>1.8683</td></tr><tr><th>20</th><td>2.09257</td></tr><tr><th>21</th><td>2.97521</td></tr><tr><th>22</th><td>2.65676</td></tr><tr><th>23</th><td>2.83908</td></tr><tr><th>24</th><td>2.95686</td></tr><tr><th>25</th><td>2.53897</td></tr><tr><th>26</th><td>3.33873</td></tr><tr><th>27</th><td>2.51366</td></tr><tr><th>28</th><td>2.00283</td></tr><tr><th>29</th><td>2.95834</td></tr><tr><th>30</th><td>2.52323</td></tr><tr><th>&vellip;</th><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& lnw\\\\\n",
       "\t\\hline\n",
       "\t& Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1.36577 \\\\\n",
       "\t2 & 2.54022 \\\\\n",
       "\t3 & 3.14226 \\\\\n",
       "\t4 & 2.43361 \\\\\n",
       "\t5 & 2.65676 \\\\\n",
       "\t6 & 2.43361 \\\\\n",
       "\t7 & 2.05094 \\\\\n",
       "\t8 & 2.49424 \\\\\n",
       "\t9 & 3.92972 \\\\\n",
       "\t10 & 2.0124 \\\\\n",
       "\t11 & 2.11021 \\\\\n",
       "\t12 & 2.83908 \\\\\n",
       "\t13 & 3.06222 \\\\\n",
       "\t14 & 2.59222 \\\\\n",
       "\t15 & 2.43361 \\\\\n",
       "\t16 & 1.69666 \\\\\n",
       "\t17 & 2.65676 \\\\\n",
       "\t18 & 2.51651 \\\\\n",
       "\t19 & 1.8683 \\\\\n",
       "\t20 & 2.09257 \\\\\n",
       "\t21 & 2.97521 \\\\\n",
       "\t22 & 2.65676 \\\\\n",
       "\t23 & 2.83908 \\\\\n",
       "\t24 & 2.95686 \\\\\n",
       "\t25 & 2.53897 \\\\\n",
       "\t26 & 3.33873 \\\\\n",
       "\t27 & 2.51366 \\\\\n",
       "\t28 & 2.00283 \\\\\n",
       "\t29 & 2.95834 \\\\\n",
       "\t30 & 2.52323 \\\\\n",
       "\t$\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m7305×1 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m lnw     \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\n",
       "──────┼─────────\n",
       "    1 │ 1.36577\n",
       "    2 │ 2.54022\n",
       "    3 │ 3.14226\n",
       "    4 │ 2.43361\n",
       "    5 │ 2.65676\n",
       "    6 │ 2.43361\n",
       "    7 │ 2.05094\n",
       "    8 │ 2.49424\n",
       "    9 │ 3.92972\n",
       "   10 │ 2.0124\n",
       "   11 │ 2.11021\n",
       "  ⋮   │    ⋮\n",
       " 7296 │ 3.14226\n",
       " 7297 │ 3.28537\n",
       " 7298 │ 2.18675\n",
       " 7299 │ 2.77454\n",
       " 7300 │ 2.8799\n",
       " 7301 │ 3.28537\n",
       " 7302 │ 2.70555\n",
       " 7303 │ 3.97851\n",
       " 7304 │ 2.72562\n",
       " 7305 │ 3.14226\n",
       "\u001b[36m7284 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = data_train[!, [\"lnw\"]] # Dataframe format\n",
    "Y_test = data_test[ !,  [\"lnw\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We start to make the regressions for every model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. OLS - Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get betas from basic regression\n",
    "fit_lm_basic = lm(formula_basic, data_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) using the basic model is equal to 0.34418046057969054"
     ]
    }
   ],
   "source": [
    "# Compute the Out-Of-Sample Performance\n",
    "yhat_lm_basic = GLM.predict( fit_lm_basic , data_test )\n",
    "res_lm_basic = ( Y_test[!,1] - yhat_lm_basic ).^2\n",
    "print(\"The mean squared error (MSE) using the basic model is equal to \" , mean( res_lm_basic ) ) # MSE OLS (basic model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.2388076180858274"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the MSE, std(MSE) and R2\n",
    "matrix_ones = ones( size(res_lm_basic)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_lm_basic )   # first argument (X), secind argument (Y)\n",
    "MSE_lm_basic = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_lm_basic = 1 .- ( MSE_lm_basic[1] / var(Y_test[!,1]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.2388076180858274"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 .- ( MSE_lm_basic[1] / var(Y_test[!,1]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. OLS - Flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get betas from flexible regression\n",
    "fit_lm_flex = lm(formula_flex, data_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) using the flexible model is equal to 0.3451138214923413"
     ]
    }
   ],
   "source": [
    "# Compute the Out-Of-Sample Performance\n",
    "yhat_lm_flex = GLM.predict( fit_lm_flex , data_test )\n",
    "res_lm_flex = ( Y_test[!,1] - yhat_lm_flex ).^2\n",
    "print(\"The mean squared error (MSE) using the flexible model is equal to \" , mean( res_lm_flex ) ) # MSE OLS (flex model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.23674338929407812"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the MSE\n",
    "matrix_ones = ones( size(res_lm_flex)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_lm_flex )   # first argument (X), secind argument (Y)\n",
    "MSE_lm_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_lm_flex = 1 .- ( MSE_lm_flex[1] / var(Y_test[!,1]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lasso - Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"GitHub/ECO224/Labs/Julia_Notebooks/hdmjl/hdmjl.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>21,912 rows × 32 columns (omitted printing of 24 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>(Intercept)</th><th>female</th><th>widowed</th><th>divorced</th><th>separated</th><th>nevermarried</th><th>hsd08</th><th>hsd911</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>1.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>1.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& (Intercept) & female & widowed & divorced & separated & nevermarried & hsd08 & hsd911 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 1.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 1.0 & 0.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 1.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m21912×32 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m (Intercept) \u001b[0m\u001b[1m female  \u001b[0m\u001b[1m widowed \u001b[0m\u001b[1m divorced \u001b[0m\u001b[1m separated \u001b[0m\u001b[1m nevermarried \u001b[0m\u001b[1m hsd\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Float64     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │         1.0      0.0      0.0       0.0        0.0           0.0      ⋯\n",
       "     2 │         1.0      1.0      0.0       0.0        0.0           0.0\n",
       "     3 │         1.0      0.0      0.0       0.0        0.0           1.0\n",
       "     4 │         1.0      0.0      0.0       0.0        0.0           0.0\n",
       "     5 │         1.0      0.0      0.0       0.0        0.0           0.0      ⋯\n",
       "     6 │         1.0      1.0      0.0       0.0        0.0           0.0\n",
       "     7 │         1.0      1.0      0.0       0.0        0.0           0.0\n",
       "     8 │         1.0      0.0      0.0       0.0        0.0           0.0\n",
       "     9 │         1.0      0.0      0.0       0.0        0.0           1.0      ⋯\n",
       "    10 │         1.0      0.0      0.0       0.0        0.0           1.0\n",
       "    11 │         1.0      0.0      0.0       0.0        0.0           0.0\n",
       "   ⋮   │      ⋮          ⋮        ⋮        ⋮          ⋮           ⋮            ⋱\n",
       " 21903 │         1.0      0.0      0.0       0.0        0.0           0.0\n",
       " 21904 │         1.0      1.0      0.0       0.0        0.0           1.0      ⋯\n",
       " 21905 │         1.0      0.0      0.0       0.0        0.0           1.0\n",
       " 21906 │         1.0      1.0      0.0       0.0        0.0           0.0\n",
       " 21907 │         1.0      1.0      0.0       0.0        0.0           0.0\n",
       " 21908 │         1.0      0.0      0.0       0.0        0.0           0.0      ⋯\n",
       " 21909 │         1.0      1.0      0.0       0.0        0.0           0.0\n",
       " 21910 │         1.0      0.0      0.0       0.0        0.0           0.0\n",
       " 21911 │         1.0      0.0      0.0       0.0        0.0           0.0\n",
       " 21912 │         1.0      0.0      0.0       0.0        0.0           0.0      ⋯\n",
       "\u001b[36m                                               26 columns and 21891 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_col1 = Symbol.(coefnames(fit_lm_basic))\n",
    "X1 = DataFrame(model_X_basic_train, names_col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.22036420343017815"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic model. Lasso sets some variables' coeff. to zero.\n",
    "\n",
    "rlasso_basic  = rlasso_arg( X1, Y_train, nothing, false, false, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "\n",
    "fit_rlasso_basic = rlasso(rlasso_basic)\n",
    "\n",
    "#Get prediction\n",
    "yhat_rlasso = model_X_basic_test*fit_rlasso_basic[\"coefficients\"] \n",
    "\n",
    "#Get erorrs^2, MSE, std(MSE) and R^2 from the regression\n",
    "res_rlasso_basic = ( Y_test[!,1] - yhat_rlasso ).^ 2\n",
    "matrix_ones = ones( size(res_rlasso_basic)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_rlasso_basic)  \n",
    "MSE_rlasso_basic = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_rlasso_basic = 1 .- ( MSE_rlasso_basic[1] / var(Y_test[!,1]) ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lasso - Flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_col1 = Symbol.(coefnames(fit_lm_flex))\n",
    "X1 = DataFrame(model_X_flex_train, names_col1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.21799742839218872"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Flexible model. Lasso sets some variables' coeff. to zero.\n",
    "\n",
    "\n",
    "rlasso_flex  = rlasso_arg( X1, Y_train, nothing, false, false, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "\n",
    "fit_rlasso_flex = rlasso(rlasso_flex)\n",
    "\n",
    "#Get prediction\n",
    "yhat_rlasso = model_X_flex_test*fit_rlasso_flex[\"coefficients\"] \n",
    "\n",
    "#Get erorrs^2, MSE, std(MSE) and R^2 from the regression\n",
    "res_rlasso_flex = ( Y_test[!,1] - yhat_rlasso ).^ 2\n",
    "matrix_ones = ones( size(res_rlasso_flex)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_rlasso_flex )  \n",
    "MSE_rlasso_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_rlasso_flex = 1 .- ( MSE_rlasso_flex[1] / var(Y_test[!,1]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Lasso CV - Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.23918712760745175"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lasso_cv   = GLMNet.glmnetcv(model_X_basic_train, Y_train[!,1], alpha=1)\n",
    "\n",
    "#We fit the model using the coefficients from each model, but using the testing sample\n",
    "yhat_lasso_cv    = GLMNet.predict(fit_lasso_cv,  model_X_basic_test)\n",
    "\n",
    "#Getting the errors^2, MSE, std(MSE) and R^2 from regression\n",
    "res_lasso_cv = ( Y_test[!,1] - yhat_lasso_cv ).^2\n",
    "matrix_ones = ones( size(res_lasso_cv)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_lasso_cv )\n",
    "MSE_lasso_cv_basic = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_lasso_cv_basic = 1 .- ( MSE_lasso_cv_basic[1] / var( Y_test[!,1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Lasso CV - Flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.23978491704457594"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lasso_cv   = GLMNet.glmnetcv(model_X_flex_train, Y_train[!,1], alpha=1)\n",
    "\n",
    "#We fit the model using the coefficients from each model, but using the testing sample\n",
    "yhat_lasso_cv    = GLMNet.predict(fit_lasso_cv,  model_X_flex_test)\n",
    "\n",
    "#Getting the errors^2, MSE, std(MSE) and R^2 from regression\n",
    "res_lasso_cv = ( Y_test[!,1] - yhat_lasso_cv ) .^ 2\n",
    "matrix_ones = ones( size(res_lasso_cv)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_lasso_cv )\n",
    "MSE_lasso_cv_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_lasso_cv_flex = 1 .- ( MSE_lasso_cv_flex[1] / var( Y_test[!,1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Ridge - Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.23762088600288211"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with training data\n",
    "fit_ridge   = GLMNet.glmnetcv(model_X_basic_train, Y_train[!,1], alpha=0) \n",
    "\n",
    "#Get the predictors\n",
    "yhat_ridge   = GLMNet.predict(fit_ridge,  model_X_basic_test)\n",
    "\n",
    "#Get the residuals squared for each obs and MSE \n",
    "res_ridge = ( Y_test[!,1] - yhat_ridge ) .^ 2\n",
    "matrix_ones = ones( size(res_ridge)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_ridge )\n",
    "MSE_ridge_basic = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "#Get the R^2 from the model\n",
    "R2_ridge_basic = 1 .- ( MSE_ridge_basic[1] / var( Y_test[!,1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Ridge - Flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.23835123306951278"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with training data\n",
    "fit_ridge   = GLMNet.glmnetcv(model_X_flex_train, Y_train[!,1], alpha=0)\n",
    "\n",
    "#Get the predictors\n",
    "yhat_ridge   = GLMNet.predict(fit_ridge,  model_X_flex_test)\n",
    "\n",
    "#Get MSE, std(MSE) and R2\n",
    "res_ridge = ( Y_test[!,1] - yhat_ridge ) .^ 2\n",
    "matrix_ones = ones( size(res_ridge)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_ridge )\n",
    "MSE_ridge_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_ridge_flex = 1 .- ( MSE_ridge_flex[1] / var( Y_test[!,1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Elastic Net - Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.23918916860114692"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with training data\n",
    "fit_elnet   = GLMNet.glmnetcv(model_X_basic_train, Y_train[!,1], alpha= 0.5)\n",
    "\n",
    "#Get the predictors\n",
    "yhat_elnet   = GLMNet.predict(fit_elnet,  model_X_basic_test)\n",
    "\n",
    "#Get MSE, std(MSE) and R2\n",
    "res_elnet = ( Y_test[!,1] - yhat_elnet ) .^ 2\n",
    "matrix_ones = ones( size(res_elnet)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_elnet )\n",
    "MSE_elnet_basic = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_elnet_basic = 1 .- ( MSE_elnet_basic[1] / var( Y_test[!,1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Elastic Net - Flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.23965737760094663"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with training data\n",
    "fit_elnet   = GLMNet.glmnetcv(model_X_flex_train, Y_train[!,1], alpha= 0.5)\n",
    "\n",
    "#Get the predictors\n",
    "yhat_elnet   = GLMNet.predict(fit_elnet,  model_X_flex_test)\n",
    "\n",
    "#Get MSE, std(MSE) and R2\n",
    "res_elnet = ( Y_test[!,1] - yhat_elnet ) .^ 2\n",
    "matrix_ones = ones( size(res_elnet)[1] ,1 )\n",
    "mean_residuals = lm(  matrix_ones, res_elnet )\n",
    "MSE_elnet_flex = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "R2_elnet_flex = 1 .- ( MSE_elnet_flex[1] / var( Y_test[!,1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ScikitLearn, DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor\n",
       "max_depth:                -1\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "root:                     nothing"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree0 = DecisionTreeRegressor(min_purity_increase = 0, min_samples_leaf=1, min_samples_split = 2,rng = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor\n",
       "max_depth:                -1\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "root:                     Decision Tree\n",
       "Leaves: 3917\n",
       "Depth:  27"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_fit0 =  ScikitLearn.fit!(tree0, model_X_basic_train, Y_train[!,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 using tree regression:0.19891936997646242"
     ]
    }
   ],
   "source": [
    "y_hat_t = ScikitLearn.predict(trees_fit0, model_X_basic_test)\n",
    "\n",
    "res_tree_noprun = ( Y_test[!,1] - y_hat_t ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_tree_noprun )\n",
    "MSE_tree_noprun = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "R2_tree_noprun = ( 1 .- ( MSE_tree_noprun[1] / var( Y_test[!,1] ) ) )[1]\n",
    "\n",
    "print(\"R^2 using tree regression:\", R2_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruned Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor\n",
       "max_depth:                -1\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.01\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "root:                     Decision Tree\n",
       "Leaves: 16\n",
       "Depth:  9"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using prun purity parameter = 0.010\n",
    "\n",
    "tree1 = DecisionTreeRegressor( min_samples_leaf=1, min_samples_split = 2, rng = 0, min_purity_increase = 0.01)\n",
    "trees_fit1 =  ScikitLearn.fit!(tree1, model_X_basic_train, Y_train[!,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 using tree regression:0.19891936997646242"
     ]
    }
   ],
   "source": [
    "y_hat_t = ScikitLearn.predict(trees_fit1, model_X_basic_test)\n",
    "\n",
    "res_tree_prun = ( Y_test[!,1] - y_hat_t ) .^ 2\n",
    "mean_residuals = lm(  matrix_ones, res_tree_prun )\n",
    "MSE_tree_prun = [ coef( mean_residuals ) , stderror( mean_residuals ) ]\n",
    "\n",
    "R2_tree_prun = ( 1 .- ( MSE_tree_prun[1] / var( Y_test[!,1] ) ) )[1]\n",
    "\n",
    "print(\"R^2 using tree regression:\", R2_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<meta charset=\"UTF-8\">\n",
       "<style>\n",
       "  table, td, th {\n",
       "      border-collapse: collapse;\n",
       "      font-family: sans-serif;\n",
       "  }\n",
       "\n",
       "  td, th {\n",
       "      border-bottom: 0;\n",
       "      padding: 4px\n",
       "  }\n",
       "\n",
       "  tr:nth-child(odd) {\n",
       "      background: #eee;\n",
       "  }\n",
       "\n",
       "  tr:nth-child(even) {\n",
       "      background: #fff;\n",
       "  }\n",
       "\n",
       "  tr.header {\n",
       "      background: navy !important;\n",
       "      color: white;\n",
       "      font-weight: bold;\n",
       "  }\n",
       "\n",
       "  tr.subheader {\n",
       "      background: lightgray !important;\n",
       "      color: black;\n",
       "  }\n",
       "\n",
       "  tr.headerLastRow {\n",
       "      border-bottom: 2px solid black;\n",
       "  }\n",
       "\n",
       "  th.rowNumber, td.rowNumber {\n",
       "      text-align: right;\n",
       "  }\n",
       "\n",
       "</style>\n",
       "<body>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr class = \"header headerLastRow\">\n",
       "      <th style = \"text-align: center;\">Model</th>\n",
       "      <th style = \"text-align: center;\">MSE</th>\n",
       "      <th style = \"text-align: center;\">S.E. for MSE</th>\n",
       "      <th style = \"text-align: center;\">R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Least Squares (basic)</td>\n",
       "      <td style = \"text-align: center;\">0.3442</td>\n",
       "      <td style = \"text-align: center;\">0.0247</td>\n",
       "      <td style = \"text-align: center;\">0.2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Least Squares (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.3451</td>\n",
       "      <td style = \"text-align: center;\">0.0248</td>\n",
       "      <td style = \"text-align: center;\">0.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Lasso (basic)</td>\n",
       "      <td style = \"text-align: center;\">0.3525</td>\n",
       "      <td style = \"text-align: center;\">0.0241</td>\n",
       "      <td style = \"text-align: center;\">0.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Lasso (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.3536</td>\n",
       "      <td style = \"text-align: center;\">0.024</td>\n",
       "      <td style = \"text-align: center;\">0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated lasso (basic)</td>\n",
       "      <td style = \"text-align: center;\">0.344</td>\n",
       "      <td style = \"text-align: center;\">0.0247</td>\n",
       "      <td style = \"text-align: center;\">0.2392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated lasso (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.3437</td>\n",
       "      <td style = \"text-align: center;\">0.0246</td>\n",
       "      <td style = \"text-align: center;\">0.2398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated ridge (basic)</td>\n",
       "      <td style = \"text-align: center;\">0.3447</td>\n",
       "      <td style = \"text-align: center;\">0.0245</td>\n",
       "      <td style = \"text-align: center;\">0.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated ridge (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.3444</td>\n",
       "      <td style = \"text-align: center;\">0.0246</td>\n",
       "      <td style = \"text-align: center;\">0.2384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated elnet (basic)</td>\n",
       "      <td style = \"text-align: center;\">0.344</td>\n",
       "      <td style = \"text-align: center;\">0.0247</td>\n",
       "      <td style = \"text-align: center;\">0.2392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Cross-Validated elnet (flexible)</td>\n",
       "      <td style = \"text-align: center;\">0.3438</td>\n",
       "      <td style = \"text-align: center;\">0.0246</td>\n",
       "      <td style = \"text-align: center;\">0.2397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Non Pruned Tree</td>\n",
       "      <td style = \"text-align: center;\">0.4109</td>\n",
       "      <td style = \"text-align: center;\">0.0251</td>\n",
       "      <td style = \"text-align: center;\">0.0912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td style = \"text-align: center;\">Pruned Tree</td>\n",
       "      <td style = \"text-align: center;\">0.3622</td>\n",
       "      <td style = \"text-align: center;\">0.0247</td>\n",
       "      <td style = \"text-align: center;\">0.1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</body>\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = NamedArray(zeros(12, 4))\n",
    "\n",
    "table[1,2:3] = [MSE_lm_basic[1][1], MSE_lm_basic[2][1]]\n",
    "table[2,2:3] = [MSE_lm_flex[1][1], MSE_lm_flex[2][1]]\n",
    "table[3,2:3] = [MSE_rlasso_basic[1][1], MSE_rlasso_basic[2][1]]\n",
    "table[4,2:3] = [MSE_rlasso_flex[1][1], MSE_rlasso_flex[2][1]]\n",
    "table[5,2:3] = [MSE_lasso_cv_basic[1][1], MSE_lasso_cv_basic[2][1]]\n",
    "table[6,2:3] = [MSE_lasso_cv_flex[1][1], MSE_lasso_cv_flex[2][1]]\n",
    "table[7,2:3] = [MSE_ridge_basic[1][1], MSE_ridge_basic[2][1]]\n",
    "table[8,2:3] = [MSE_ridge_flex[1][1], MSE_ridge_flex[2][1]]\n",
    "table[9,2:3] = [MSE_elnet_basic[1][1], MSE_elnet_basic[2][1]]\n",
    "table[10,2:3] = [MSE_elnet_flex[1][1], MSE_elnet_flex[2][1]]\n",
    "table[11,2:3] = [MSE_tree_noprun[1][1], MSE_tree_noprun[2][1]]\n",
    "table[12,2:3] = [MSE_tree_prun[1][1], MSE_tree_prun[2][1]]\n",
    "\n",
    "table[1,4] = R2_lm_basic[1]\n",
    "table[2,4] = R2_lm_flex[1]\n",
    "table[3,4] = R2_rlasso_basic[1]\n",
    "table[4,4] = R2_rlasso_flex[1]\n",
    "table[5,4] = R2_lasso_cv_basic[1]\n",
    "table[6,4] = R2_lasso_cv_flex[1]\n",
    "table[7,4] = R2_ridge_basic[1]\n",
    "table[8,4] = R2_ridge_flex[1]\n",
    "table[9,4] = R2_elnet_basic[1]\n",
    "table[10,4] = R2_elnet_flex[1]\n",
    "table[11,4] = R2_tree_noprun[1]\n",
    "table[12,4] = R2_tree_prun[1]\n",
    "\n",
    "T = DataFrame(table, [ :\"Model\",:\"MSE\", :\"S.E. for MSE\", :\"R-squared\"]) \n",
    "T[!,:Model] = string.(T[!,:Model]) \n",
    "\n",
    "T[1,1] = \"Least Squares (basic)\"\n",
    "T[2,1] = \"Least Squares (flexible)\"\n",
    "T[3,1] = \"Lasso (basic)\"\n",
    "T[4,1] = \"Lasso (flexible)\"\n",
    "T[5,1] = \"Cross-Validated lasso (basic)\"\n",
    "T[6,1] = \"Cross-Validated lasso (flexible)\"\n",
    "T[7,1] = \"Cross-Validated ridge (basic)\"\n",
    "T[8,1] = \"Cross-Validated ridge (flexible)\"\n",
    "T[9,1] = \"Cross-Validated elnet (basic)\"\n",
    "T[10,1] = \"Cross-Validated elnet (flexible)\"\n",
    "T[11,1] = \"Non Pruned Tree\"\n",
    "T[12,1] = \"Pruned Tree\"\n",
    "\n",
    "header = ([\"Model\", \"MSE\", \"S.E. for MSE\", \"R-squared\"])\n",
    "\n",
    "pretty_table(T; backend = Val(:html), header = header, formatters=ft_round(4), alignment=:c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, it will impossible to use a linear regression to predict well. So, tree regression would be a good option. In this case, it is neccesary to  divide the predictor space, which is the set of values of $X1, X2,..., Xp$ in non-overlapping regions $R1, R2, ..., RJ$, where we can analyze which variables are more related to the output for each one. Apart from that, we divide the sample in two groups: training and test. To construct the tree, we use the training data and the goal is to minimize the RSS given by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{j=1}^{J}\\sum_{i\\in R_j}(y_i - \\hat{y}R_j)^2 \n",
    "\\end{equation}\n",
    "\n",
    "The prediction is simply the mean of the values for training observations in region $Rj$.\n",
    "\n",
    "### To build a tree regression using a single predictor you need to follow the next steps:\n",
    "1. Step 1\n",
    "- Given a training data, we want to build a regression tree that uses the variable $X$ to predict the variable $Y$. Let's say that X is drug dose and Y is drug effectiveness.\n",
    "2. Step 2\n",
    "- Just like a clasification trees, the first thing we do for a regression tree is decide what goes in the root.\n",
    "3. Step 3\n",
    "- To make the decision, we calculate the average of the first 2 doses, wich is 3. Then, we buld a very simple tree that splits the measurements in two groups based on whether or not the dose < 3. \n",
    "4. Step 4\n",
    "- Because only one point has a dose < 3, and its average effectiveness is 0, we put 0 and in the corresponding leaf.\n",
    "- All other points have dose >= 3, and their effectiveness is 38.8, so we put 38.8 in the other leaf.\n",
    "5. Step 5\n",
    "- Assuming the following: for the one point with dose < 3, the regression tree makes a good prediction.\n",
    "6. Setp 6\n",
    "- Assuming the following: for the one point with dose >= 3, the regression tree makes a bad prediction.\n",
    "7. Setp 7\n",
    "- We can visualiaze how good or bad the regression trees is at making predictions by drawning the residuals, the differences between the observed and predicted values.\n",
    "- We can also quantify how good or bad the predictions are by calculating the Sum of the Squared Residuals (SSR).\n",
    "- Lastly, we can compare the SSR for different thresholds by plotting them on this graph, wich has dose on the x-axis and SSR on the y-axis.\n",
    "8. Step 8\n",
    "- Looking at the SSRs for each dose thershold, the root will be the thershold that had the smaller SSR.\n",
    "9. Step 9\n",
    "- If It's necessary, we will repeat step 7 and 8 to split the tree and add more nodes to it.\n",
    "10. Setp 10 \n",
    "\n",
    "### To build a regression tree with multiple features\n",
    "1. Step 1\n",
    "- For each predictor we select the thershold that give us the smallest SSR. However, instead of that threshold instantly becoming the root, it only becomes a candidate for the root.\n",
    "\n",
    "2. Step 2\n",
    "- The root will be the candidate with the  lowest SSR.\n",
    "\n",
    "3. Step 3\n",
    "- If It's necessary, you repeat the same process for each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is it important to prune a tree? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prune a tree to penalize the inclusion of leaves. This is to avoid overfitting with the training observations. So, cutting down the branches, we can improve the predictive perfomance.\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{m=1}^{|T|}\\sum_{i: x_i\\in R_m}(y_i - \\hat{y}_{R_m})^2 +\\alpha|T|   T \\subset T_o\n",
    "\\end{equation}\n",
    "\n",
    "Where: T indicates the number of leaves of the tree T, R_m is the region corresponding to the mth terminal node and $\\hat{y}_{R_j}$ is the same as before. $\\alpha$ is the value of penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.6",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
